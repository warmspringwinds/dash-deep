{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import tools\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class BaseGraph():\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.iteration_counter = 0\n",
    "        \n",
    "        # Creating two subplots with two columns\n",
    "        figure_obj = tools.make_subplots(rows=1, cols=2,\n",
    "                                         subplot_titles=('Losses', 'Accuracy'))\n",
    "        \n",
    "        # Creating curves for val/train accuracy/loss curves\n",
    "        training_loss_curve_trace = go.Scatter(\n",
    "                                            x=[],\n",
    "                                            y=[],\n",
    "                                            name = 'Training loss')\n",
    "\n",
    "        validation_loss_curve_trace = go.Scatter(\n",
    "                                            x=[],\n",
    "                                            y=[],\n",
    "                                            name = 'Validation loss')\n",
    "\n",
    "        training_accuracy_curve_trace = go.Scatter(\n",
    "                                            x=[],\n",
    "                                            y=[],\n",
    "                                            name = 'Training accuracy')\n",
    "\n",
    "\n",
    "        validation_accuracy_curve_trace = go.Scatter(\n",
    "                                            x=[],\n",
    "                                            y=[],\n",
    "                                            name = 'Validation accuracy')\n",
    "\n",
    "        # associating our scatter objects with each subplot\n",
    "        figure_obj.append_trace(training_loss_curve_trace, 1, 1)\n",
    "        figure_obj.append_trace(validation_loss_curve_trace, 1, 1)\n",
    "        figure_obj.append_trace(training_accuracy_curve_trace, 1, 2)\n",
    "        figure_obj.append_trace(validation_accuracy_curve_trace, 1, 2)\n",
    "\n",
    "        #figure_obj['layout'].update(height=height,\n",
    "        #                            width=width)\n",
    "        \n",
    "        # Plotly's Figure objects are not serializable,\n",
    "        # therefore we convert them into ordered dict and serilize\n",
    "        # later to store in the pickle format inside of our db.\n",
    "        self.figure_obj = figure_obj.get_ordered()\n",
    "        \n",
    "        # Creating sym links for all curves,\n",
    "        # so that we can easily update the object\n",
    "        self.training_loss_history = self.figure_obj['data'][0]\n",
    "        self.validation_loss_history = self.figure_obj['data'][1]\n",
    "        self.training_accuracy_history = self.figure_obj['data'][2]\n",
    "        self.validation_accuracy_history = self.figure_obj['data'][3]\n",
    "    \n",
    "    \n",
    "    def add_next_iteration_results(self,\n",
    "                                   training_loss,\n",
    "                                   validation_loss,\n",
    "                                   training_accuracy,\n",
    "                                   validation_accuracy):\n",
    "        \n",
    "        \n",
    "        self.training_loss_history['x'].append(self.iteration_counter)\n",
    "        self.validation_loss_history['x'].append(self.iteration_counter)\n",
    "        self.training_accuracy_history['x'].append(self.iteration_counter)\n",
    "        self.validation_accuracy_history['x'].append(self.iteration_counter)\n",
    "        self.iteration_counter += 1\n",
    "        \n",
    "        self.training_loss_history['y'].append(training_loss)\n",
    "        self.validation_loss_history['y'].append(validation_loss)\n",
    "        self.training_accuracy_history['y'].append(training_accuracy)\n",
    "        self.validation_accuracy_history['y'].append(validation_accuracy)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pebble\n",
    "from time import sleep\n",
    "\n",
    "process_pool = pebble.ProcessPool(max_tasks=1)\n",
    "\n",
    "def dummy_func():\n",
    "    \n",
    "    #sleep(1000)\n",
    "    return 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_obj = process_pool.schedule(dummy_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_obj.exception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8273446899669058"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy = BaseGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy.add_next_iteration_results(1, 1, 1, 1)\n",
    "dummy.add_next_iteration_results(2, 2, 2, 2)\n",
    "dummy.add_next_iteration_results(3, 3, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('data',\n",
       "              [OrderedDict([('x', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]),\n",
       "                            ('y', [1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]),\n",
       "                            ('name', 'Training loss'),\n",
       "                            ('type', 'scatter'),\n",
       "                            ('xaxis', 'x1'),\n",
       "                            ('yaxis', 'y1')]),\n",
       "               OrderedDict([('x', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]),\n",
       "                            ('y', [1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]),\n",
       "                            ('name', 'Validation loss'),\n",
       "                            ('type', 'scatter'),\n",
       "                            ('xaxis', 'x1'),\n",
       "                            ('yaxis', 'y1')]),\n",
       "               OrderedDict([('x', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]),\n",
       "                            ('y', [1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]),\n",
       "                            ('name', 'Training accuracy'),\n",
       "                            ('type', 'scatter'),\n",
       "                            ('xaxis', 'x2'),\n",
       "                            ('yaxis', 'y2')]),\n",
       "               OrderedDict([('x', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]),\n",
       "                            ('y', [1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]),\n",
       "                            ('name', 'Validation accuracy'),\n",
       "                            ('type', 'scatter'),\n",
       "                            ('xaxis', 'x2'),\n",
       "                            ('yaxis', 'y2')])]),\n",
       "             ('layout',\n",
       "              OrderedDict([('annotations',\n",
       "                            [OrderedDict([('x', 0.225),\n",
       "                                          ('y', 1.0),\n",
       "                                          ('font',\n",
       "                                           OrderedDict([('size', 16)])),\n",
       "                                          ('showarrow', False),\n",
       "                                          ('text', 'Losses'),\n",
       "                                          ('xanchor', 'center'),\n",
       "                                          ('xref', 'paper'),\n",
       "                                          ('yanchor', 'bottom'),\n",
       "                                          ('yref', 'paper')]),\n",
       "                             OrderedDict([('x', 0.775),\n",
       "                                          ('y', 1.0),\n",
       "                                          ('font',\n",
       "                                           OrderedDict([('size', 16)])),\n",
       "                                          ('showarrow', False),\n",
       "                                          ('text', 'Accuracy'),\n",
       "                                          ('xanchor', 'center'),\n",
       "                                          ('xref', 'paper'),\n",
       "                                          ('yanchor', 'bottom'),\n",
       "                                          ('yref', 'paper')])]),\n",
       "                           ('xaxis1',\n",
       "                            OrderedDict([('anchor', 'y1'),\n",
       "                                         ('domain', [0.0, 0.45])])),\n",
       "                           ('xaxis2',\n",
       "                            OrderedDict([('anchor', 'y2'),\n",
       "                                         ('domain', [0.55, 1.0])])),\n",
       "                           ('yaxis1',\n",
       "                            OrderedDict([('anchor', 'x1'),\n",
       "                                         ('domain', [0.0, 1.0])])),\n",
       "                           ('yaxis2',\n",
       "                            OrderedDict([('anchor', 'x2'),\n",
       "                                         ('domain', [0.0, 1.0])]))]))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy.figure_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name db",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8feff2a33cba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwtforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqlalchemy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdash_deep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscripts_db_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdash_deep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidjets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidjets_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_widjet_from_form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdash_deep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_wtform_instances_and_input_form_widjets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daniil/repos/dash-deep/dash_deep/app.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdash_deep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTaskManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclick\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daniil/repos/dash-deep/dash_deep/task.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mpebble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlaunch_process_patched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdash_deep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTaskManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name db"
     ]
    }
   ],
   "source": [
    "from wtforms import Form\n",
    "\n",
    "from wtforms.ext.sqlalchemy.orm import model_form\n",
    "from dash_deep.app import scripts_db_models\n",
    "from dash_deep.widjets.widjets_factory import generate_widjet_from_form\n",
    "from dash_deep.utils import generate_wtform_instances_and_input_form_widjets\n",
    "from dash_deep.app import db\n",
    "from dash_deep.models import EndovisBinary\n",
    "\n",
    "from plotly.graph_objs import Figure\n",
    "\n",
    "from plotly import tools\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from dash_deep.sql import create_dummy_endovis_records\n",
    "from dash_deep.app import scripts_db_models\n",
    "\n",
    "wtform_classes, scripts_input_form_widjets = generate_wtform_instances_and_input_form_widjets(scripts_db_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_form = wtform_classes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_form.batch_size.data = 1000\n",
    "imagenet_form.learning_rate.data = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 1000, 'learning_rate': 0.0001}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagenet_form.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_model = imagenet_form.sql_model_class()\n",
    "\n",
    "imagenet_form.populate_obj(sql_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.engine.dispose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Imagenet classification experiment batch_size=1000, learning_rate=0.0001, graphs=None>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm.attributes import flag_modified\n",
    "\n",
    "class Experiment():\n",
    "    \n",
    "    def __init__(self, sql_model_instance):\n",
    "        \n",
    "        self.sql_model_instance = sql_model_instance\n",
    "        \n",
    "        # Since experiment will be most probably run in a separate,\n",
    "        # process, we need to take appropriate actions to prevent different\n",
    "        # processes from using the same connection:\n",
    "        # http://docs.sqlalchemy.org/en/latest/core/pooling.html#using-connection-pools-with-multiprocessing\n",
    "        db.engine.dispose()\n",
    "        self.db = db\n",
    "        \n",
    "        # Making an initial commit to the database\n",
    "        self.db.session.add(self.sql_model_instance)\n",
    "        self.commit()\n",
    "        \n",
    "    def add_next_iteration_results(self, *args, **kwargs):\n",
    "        \n",
    "        # Passing all the parameters to the graph object\n",
    "        # which upates the internal state of the graph\n",
    "        self.sql_model_instance.graphs.add_next_iteration_results(*args, **kwargs)\n",
    "        \n",
    "        # Since we pickle this field -- we need to explicitly tell that\n",
    "        # the field was updated, otherwise the changes won't be commited\n",
    "        flag_modified(self.sql_model_instance, 'graphs')\n",
    "        \n",
    "        self.db.session.add(self.sql_model_instance)\n",
    "        self.commit()\n",
    "    \n",
    "    def finish(self):\n",
    "        \n",
    "        # Compute the best results for each metric using graph object:\n",
    "        # like highest accuracy + lowest loss -- and write them down\n",
    "        # into database\n",
    "        \n",
    "        # Should we close the db session?\n",
    "        \n",
    "        self.db.session.add(self.sql_model_instance)\n",
    "        self.commit()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def another(*args, **kwargs):\n",
    "    \n",
    "    print(args, kwargs)\n",
    "\n",
    "def test(first, *args, **kwargs):\n",
    "    \n",
    "    print(first, args, kwargs)\n",
    "    \n",
    "    another(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, (100,), {'name': 'danniil'})\n",
      "((100,), {'name': 'danniil'})\n"
     ]
    }
   ],
   "source": [
    "test(1, 100, name='danniil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n",
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n",
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n",
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n",
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n",
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n",
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n",
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n",
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n",
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_model_instances_list = create_dummy_endovis_records(10)\n",
    "\n",
    "db.session.add_all(dummy_model_instances_list)\n",
    "db.session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Endovis Binary Segmentation experiment id=1, batch_size=100, learning_rate=0.0001>, output_stride=8, graphs=<dash_deep.plot.BaseSegmentationGraph instance at 0x7fad3b0f30e0>, <Endovis Binary Segmentation experiment id=2, batch_size=100, learning_rate=0.0001>, output_stride=8, graphs=<dash_deep.plot.BaseSegmentationGraph instance at 0x7fad3b5ba518>, <Endovis Binary Segmentation experiment id=3, batch_size=100, learning_rate=0.0001>, output_stride=8, graphs=<dash_deep.plot.BaseSegmentationGraph instance at 0x7fad3b2069e0>, <Endovis Binary Segmentation experiment id=4, batch_size=100, learning_rate=0.0001>, output_stride=8, graphs=<dash_deep.plot.BaseSegmentationGraph instance at 0x7fad3b396290>, <Endovis Binary Segmentation experiment id=5, batch_size=100, learning_rate=0.0001>, output_stride=8, graphs=<dash_deep.plot.BaseSegmentationGraph instance at 0x7fad3b0dc368>]\n"
     ]
    }
   ],
   "source": [
    "experiments = EndovisBinary.query.all()\n",
    "print(experiments)\n",
    "\n",
    "first_experiment = experiments[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
